{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "833fe6a5",
   "metadata": {},
   "source": [
    "# Crop Seed Segmentation Guide for Sorghum Seed\n",
    "\n",
    "A lot of the codes are adapted from Toda et al. 2020\n",
    "Their github: https://github.com/totti0223/crop_seed_instance_segmentation.git\n",
    "\n",
    "Download the models from their github page, I provided the link here just in case:\n",
    "The folder is named \"data\".\n",
    "Link: https://drive.google.com/file/d/1g8bg9ter9DlKWgs0lfPZMQemRlzRVOQr/view?usp=sharing\n",
    "\n",
    "# Let's import all the modules needed for this notebook: \n",
    "\n",
    "1. warnings\n",
    "2. scikit-image\n",
    "3. sys\n",
    "4. numpy\n",
    "5. pathlib\n",
    "6. opencv\n",
    "7. pandas\n",
    "8. tensorflow >= 2.10.0\n",
    "9. keras\n",
    "10. os\n",
    "11. pytesseract\n",
    "12. matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc04bd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-28 11:00:44.417249: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.10.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')  #general warning suppression\n",
    "import skimage.io\n",
    "import sys\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "import cv2 as cv ##opencv\n",
    "from skimage.measure import label, regionprops, regionprops_table\n",
    "import pandas as pd\n",
    "import tensorflow as tf \n",
    "import keras.backend as K \n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  #tensorflow deprecration warning suppression\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats = {'png', 'retina'}\n",
    "import pytesseract\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ba305c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask_RCNN directory already exists\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"Mask-RCNN\"):\n",
    "    !git clone https://github.com/NikeeShrestha/Mask-RCNN.git ##this is adapted for tensorflow 2.10.0\n",
    "    print(\"Cloned repository\")\n",
    "else:\n",
    "    print(\"Mask_RCNN directory already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "875d9fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(\"Mask-RCNN\") \n",
    "\n",
    "from mrcnn.visualize import display_images\n",
    "from mrcnn.model import log\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils, visualize\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b6bdbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(Config):  ##Config is the modellib fucntion of Mask-RCNN\n",
    "    NAME = \"seed\" ##you can name it anything\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    NUM_CLASSES = 1 + 1  # background + 1 seeds\n",
    "    IMAGE_MIN_DIM = 512\n",
    "    IMAGE_MAX_DIM = 8192\n",
    "    DETECTION_MAX_INSTANCES = 1000\n",
    "    IMAGE_RESIZE_MODE = \"pad64\"\n",
    "    RPN_NMS_THRESHOLD = 0.4\n",
    "    DETECTION_MIN_CONFIDENCE = 0\n",
    "\n",
    "config = InferenceConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f72b9f",
   "metadata": {},
   "source": [
    "# Load the model with specific directory when model is saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bf46229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/schnablelab/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "WARNING:tensorflow:From /home/schnablelab/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "model weights loaded\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "model = modellib.MaskRCNN(mode=\"inference\", config=config, model_dir=\".\") \n",
    "##mode=inference means you want to use pre-trained model and predict on the image\n",
    "model.load_weights(\"data/other/model_weights/rice.h5\", by_name=True) ##I am using rice model but if you want, you can use wheat model as well. It won't segment each seed in the image though.\n",
    "print(\"model weights loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d672fd",
   "metadata": {},
   "source": [
    "# Segmentation and Data extraction; Length, Width, Area and three Color Channels\n",
    "\n",
    "Cropping image should be customized based on the dimension of your image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08f78f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_directory=\"rawimages/Tutorial/\"\n",
    "Processed_image_directory=\"rawimages/processed/\"\n",
    "path1=Path(path_directory) ## Directory where your raw images area \n",
    "path=path1.glob(\"*.jpg\") ##My images are in \"jpg\" format\n",
    "\n",
    "MorphologicalData=[]\n",
    "for i in path:\n",
    "    img=cv.imread(str(i))##converting i into string with str function\n",
    "    seed_tag=img[2800:3500,0:800] ##Cropping the seed tag\n",
    "    thresh, seed_bw = cv.threshold(seed_tag, 155, 255, cv.THRESH_BINARY) ##Change to binary\n",
    "    print(i)\n",
    "    text=pytesseract.image_to_string(seed_bw ,config='--psm 6 --oem 3 -c tessedit_char_whitelist=0123456789') ##recognize the text\n",
    "    text=text.strip() ##remove /n from text\n",
    "    print(text) ##print plotID\n",
    "    seed_grain=img[1410:2610,645:1815] \n",
    "    seed_grain=cv.GaussianBlur(seed_grain,(5,5),0) \n",
    "    seed_gray=cv.cvtColor(seed_grain, cv.COLOR_BGR2GRAY) ##convert to grayscale\n",
    "    thresh, img_bw = cv.threshold(seed_gray, 45, 255, cv.THRESH_BINARY) ##convert to binary with anything vale of 65 changes to white color\n",
    "    masked= cv.bitwise_and(seed_grain, seed_grain, mask=img_bw) ##Masking together \n",
    "    cv.imwrite(Processed_image_directory + str(text) + \"_\" + os.path.basename(str(i)), masked) ##saving the picture\n",
    "    \n",
    "    results = model.detect([masked], verbose=1)\n",
    "    r = results[0] \n",
    "    mask1=r['masks']\n",
    "    visualize.display_instances(\n",
    "            masked, r['rois'], r['masks'], r['class_ids'],\n",
    "            [\"\",\"\"], [\"\" for x in range(len(r['scores']))],\n",
    "            show_bbox=True, show_mask=True,\n",
    "            title=\"\")\n",
    "    \n",
    "    ##Region Properties\n",
    "    temp_morphologydata=[]\n",
    "\n",
    "    for i in range(r['rois'].shape[0]):\n",
    "        singlemaskpred=r['masks'][:,:,i]\n",
    "        props=skimage.measure.regionprops(singlemaskpred.astype(int))[0]\n",
    "        area=props.area\n",
    "        major_axis_length=props.major_axis_length\n",
    "        minor_axis_length=props.minor_axis_length\n",
    "        temp_morphologydata.append({\n",
    "            'area':area,\n",
    "            'major_axis_length':major_axis_length,\n",
    "            'minor_axis_length':minor_axis_length\n",
    "        })\n",
    "        # count=count+1\n",
    "    df=pd.DataFrame(temp_morphologydata)\n",
    "    df = df.drop(df['area'].idxmax()) ##Dropping the maximum data of area because sometimes huge masks are created and we do not want to consider it while taking the average.\n",
    "    df = df.drop(df['area'].idxmin()) ##Dropping the minimum data of area because sometimes small particles can be segmented.\n",
    "    \n",
    "    ##Parameters that we measure\n",
    "    Label=mask1.shape[-1]\n",
    "    imagename=os.path.basename(str(i))\n",
    "    Area=df.mean()['area']\n",
    "    Length=df.mean()['major_axis_length']\n",
    "    Width=df.mean()['minor_axis_length']\n",
    "    # EquivalentDiameter=df.mean()['equivalent_diameter']\n",
    "    \n",
    "    ##RGB extraction\n",
    "    B=[]\n",
    "    G=[]\n",
    "    R=[]\n",
    "    for i in range(r['masks'].shape[-1]):\n",
    "        mask = r['masks'][:, :, i]\n",
    "        color=pd.DataFrame(seed_grain[mask])\n",
    "        B.append(color.mean()[0])\n",
    "        G.append(color.mean()[1])\n",
    "        R.append(color.mean()[2])\n",
    "    print(\"done\")\n",
    "    AverageB=sum(B)/len(B)\n",
    "    AverageG=sum(G)/len(G)\n",
    "    AverageR=sum(R)/len(R)\n",
    "    \n",
    "    #creating dictionary ##You can edit it based on what you want\n",
    "    MorphologicalData.append(\n",
    "        {\n",
    "            'imagename': imagename,\n",
    "            'PlotID': text,\n",
    "            'Count': Label,\n",
    "            'Area': Area,\n",
    "            'Length': Length,\n",
    "            'Width': Width,\n",
    "            'AverageB':AverageB,\n",
    "            'AverageG':AverageG,\n",
    "            'AverageR':AverageR  \n",
    "        }\n",
    "    )\n",
    "  \n",
    "MorphologicalData=pd.DataFrame(MorphologicalData)\n",
    "MorphologicalData.to_csv(path_directory + \"MorphologicalData.csv\") ##Saving the data extracted in csv file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
